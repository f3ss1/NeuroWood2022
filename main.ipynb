{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from cv2 import imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F, CrossEntropyLoss\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from albumentations import HorizontalFlip, VerticalFlip, Resize, Compose\n",
    "from albumentations.augmentations.transforms import Normalize\n",
    "\n",
    "import torchvision\n",
    "\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mf3ss1\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.14 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\fess0\\iCloudDrive\\GitHub\\NeuroWood2022\\wandb\\run-20220412_174401-1k3kwz7u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/f3ss1/NeuroWood2022/runs/1k3kwz7u\" target=\"_blank\">ancient-sound-32</a></strong> to <a href=\"https://wandb.ai/f3ss1/NeuroWood2022\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/f3ss1/NeuroWood2022/runs/1k3kwz7u?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1a6bd1e4fa0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(project=\"NeuroWood2022\", entity=\"f3ss1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "class SETUP:\n",
    "    DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    BATCH_SIZE = 4\n",
    "    SIZE = 1024\n",
    "\n",
    "def transform(x):\n",
    "    if (x == 0):\n",
    "        return x\n",
    "    elif (x == 1):\n",
    "        return x\n",
    "    else:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IMG_0581</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMG_0583</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IMG_0584</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IMG_0585</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IMG_0589</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  class\n",
       "0  IMG_0581      1\n",
       "1  IMG_0583      1\n",
       "2  IMG_0584      1\n",
       "3  IMG_0585      1\n",
       "4  IMG_0589      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "data = data.sort_values('id').reset_index().drop('index', axis=1)\n",
    "data['class'] = data['class'].astype(int)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id  class\n",
       "0  1    NaN\n",
       "1  2    NaN\n",
       "2  3    NaN\n",
       "3  4    NaN\n",
       "4  5    NaN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dataframe = pd.read_csv('sample_submission.csv')\n",
    "output_dataframe['id'] = output_dataframe['id'].astype(str)\n",
    "output_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WoodDataset(Dataset):\n",
    "    def __init__(self, create_train=True) -> None:\n",
    "        \n",
    "        self.transform = Compose([Resize(SETUP.SIZE, SETUP.SIZE), Normalize()])\n",
    "        self.create_train = create_train\n",
    "        \n",
    "        \n",
    "    \n",
    "    def __getitem__(self, index) -> dict:\n",
    "        \n",
    "        if self.create_train:\n",
    "            id = data.iloc[index]['id']\n",
    "            image = imread(f'Data/Train/{id}.png').astype(np.float32)\n",
    "            processed_image = self.transform(image=image)\n",
    "            return np.moveaxis(processed_image['image'], 2, 0), torch.tensor(data.iloc[index]['class'], dtype=torch.int64)\n",
    "        else:\n",
    "            id = output_dataframe.iloc[index]['id']\n",
    "            image = imread(f'Data/Test/{id}.png').astype(np.float32)\n",
    "            processed_image = self.transform(image=image)\n",
    "            return np.moveaxis(processed_image['image'], 2, 0)\n",
    "\n",
    "            \n",
    "\n",
    "    def __len__(self) -> None:\n",
    "        if self.create_train:\n",
    "            return data.shape[0]\n",
    "        else:\n",
    "            return output_dataframe.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = WoodDataset()\n",
    "test_dataset = WoodDataset(create_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=SETUP.BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=SETUP.BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_dataloader, criterion, optimizer, device=SETUP.DEVICE):\n",
    "    rolling_loss = 0\n",
    "    for images, labels in tqdm(train_dataloader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        y_pred = model.forward(images)\n",
    "        loss = criterion(y_pred, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        rolling_loss += loss.detach().cpu().numpy()\n",
    "    return rolling_loss / len(train_dataloader)\n",
    "\n",
    "def train(model, train_dataloader, criterion, optimizer, device=SETUP.DEVICE, n_epochs=10):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    for _ in range(n_epochs):\n",
    "        loss = train_one_epoch(model, train_dataloader, criterion, optimizer, device)\n",
    "        wandb.log({\"loss\": loss})\n",
    "\n",
    "def predict(model, test_dataloader, device=SETUP.DEVICE):\n",
    "    model = model.to(device)\n",
    "    predicted_labels = torch.tensor([]).to(device)\n",
    "    for images in tqdm(test_dataloader):\n",
    "        images = images.to(device)\n",
    "        y_pred = model.forward(images)\n",
    "        predicted_labels = torch.cat((predicted_labels, y_pred.argmax(1).detach()), 0)\n",
    "    return predicted_labels.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelFinal(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelFinal, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            torchvision.models.resnet18(pretrained=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1000, 3),\n",
    "            nn.Softmax(dim=0)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelFinal()\n",
    "\n",
    "parameters = {\n",
    "    'optimizer' : SGD(model.parameters(), lr=0.01),\n",
    "    'criterion' : CrossEntropyLoss(),\n",
    "    'device' : SETUP.DEVICE,\n",
    "    'n_epochs' : 10\n",
    "}\n",
    "\n",
    "wandb.config = {\n",
    "  \"learning_rate\": \"default\",\n",
    "  \"epochs\": parameters['n_epochs'],\n",
    "  \"batch_size\": SETUP.BATCH_SIZE,\n",
    "  \"Network\": \"Resnet18 + Softmax\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 145/145 [02:34<00:00,  1.06s/it]\n",
      "100%|██████████| 145/145 [02:26<00:00,  1.01s/it]\n",
      "100%|██████████| 145/145 [02:25<00:00,  1.00s/it]\n",
      "100%|██████████| 145/145 [02:26<00:00,  1.01s/it]\n",
      "100%|██████████| 145/145 [02:26<00:00,  1.01s/it]\n",
      "100%|██████████| 145/145 [02:26<00:00,  1.01s/it]\n",
      "100%|██████████| 145/145 [02:33<00:00,  1.06s/it]\n",
      "100%|██████████| 145/145 [02:28<00:00,  1.02s/it]\n",
      "100%|██████████| 145/145 [02:27<00:00,  1.02s/it]\n",
      "100%|██████████| 145/145 [02:29<00:00,  1.03s/it]\n"
     ]
    }
   ],
   "source": [
    "train(model, train_dataloader, **parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:58<00:00,  1.07it/s]\n"
     ]
    }
   ],
   "source": [
    "predicts = predict(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 0., 2., 0., 1., 2., 0., 2., 1., 0., 1., 0., 2., 1., 1., 1., 2.,\n",
       "        0., 0., 1., 2., 2., 2., 1., 2., 0., 2., 2., 1., 1., 0., 1., 0., 2., 1.,\n",
       "        2., 1., 1., 0., 1., 0., 2., 0., 1., 2., 0., 2., 1., 0., 1., 2., 1., 2.,\n",
       "        2., 0., 2., 1., 0., 1., 2., 2., 1., 2., 0., 2., 1., 2., 2., 1., 2., 0.,\n",
       "        2., 0., 0., 1., 2., 0., 1., 2., 2., 0., 1., 1., 2., 2., 1., 0., 0., 2.,\n",
       "        1., 1., 0., 2., 2., 1., 1., 0., 2., 2., 0., 2., 1., 1., 1., 1., 2., 1.,\n",
       "        0., 2., 2., 1., 0., 0., 2., 1., 2., 0., 1., 2., 2., 0., 1., 1., 0., 2.,\n",
       "        1., 1., 1., 1., 2., 0., 2., 2., 0., 1., 1., 0., 0., 2., 0., 2., 1., 0.,\n",
       "        2., 2., 0., 1., 0., 1., 1., 1., 2., 1., 1., 1., 2., 2., 1., 0., 2., 0.,\n",
       "        2., 1., 0., 0., 1., 1., 0., 2., 2., 1., 1., 2., 1., 0., 2., 1., 2., 1.,\n",
       "        0., 2., 1., 1., 0., 1., 2., 0., 2., 1., 0., 1., 2., 0., 2., 1., 2., 1.,\n",
       "        2., 2., 1., 0., 0., 2., 1., 0., 2., 1., 0., 1., 0., 2., 1., 0., 2., 2.,\n",
       "        1., 2., 1., 0., 2., 1., 0., 1., 2., 0., 1., 2., 0., 2., 1., 2., 0., 2.,\n",
       "        1., 2., 1., 0., 2., 0., 0., 2., 1., 2., 1., 0., 2., 0., 0.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dataframe['class'] = predicts\n",
    "output_dataframe['class'] = output_dataframe['class'].astype(int)\n",
    "output_dataframe['class'] = output_dataframe['class'].apply(transform)\n",
    "output_dataframe.to_csv('prediction.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
